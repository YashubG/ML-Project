{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC2qotxDM5rChHaT5UCz9g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashubG/ML-Project/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PU_KwWyh1r_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import the datasets"
      ],
      "metadata": {
        "id": "gaNC5J7TiS3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/ML_project/test.csv')\n",
        "train = pd.read_csv('/content/ML_project/train.csv')"
      ],
      "metadata": {
        "id": "uPwPLOHWiVl3",
        "outputId": "3e4289fa-a2c0-4b4c-d70e-3957dd0a2803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/ML_project/test.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-648945056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/ML_project/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/ML_project/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ML_project/test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "vk7tbFaVjWdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop((train[(train['UsableArea'] > 4000) & (train['HotelValue'] < 300000)].index),\n",
        "           inplace=True)  # Remove obvious outliers\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "y = np.log1p(train['HotelValue'])    # Log-transform target for symmetry\n",
        "train_ids = train['Id']\n",
        "test_ids  = test['Id']\n",
        "\n",
        "# Drop ID and target from features\n",
        "train.drop(['Id','HotelValue'], axis=1, inplace=True)\n",
        "test.drop('Id', axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Combine for Preprocessing\n",
        "# ---------------------------\n",
        "all_data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Drop Sparse/Irrelevant Features\n",
        "# ---------------------------\n",
        "# Remove columns with mostly missing or poor information\n",
        "drop_cols = [\n",
        "    'ServiceLaneType','FacadeType','PoolQuality','BoundaryFence','ExtraFacility',\n",
        "    'PlotConfiguration','NearbyTransport1','NearbyTransport2','UtilityAccess'\n",
        "]\n",
        "all_data.drop(columns=[c for c in drop_cols if c in all_data.columns], inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Feature Engineering\n",
        "# ---------------------------\n",
        "# Convert some numeric categories to strings (for one-hot later)\n",
        "all_data['PropertyClass'] = all_data['PropertyClass'].astype(str)\n",
        "\n",
        "# Area and Room features\n",
        "all_data['TotalSF'] = (\n",
        "    all_data['BasementTotalSF'] +\n",
        "    all_data['GroundFloorArea'] +\n",
        "    all_data['UpperFloorArea']\n",
        ")\n",
        "all_data['TotalBath'] = (\n",
        "    all_data['FullBaths'] +\n",
        "    0.5 * all_data['HalfBaths'] +\n",
        "    all_data['BasementFullBaths'] +\n",
        "    0.5 * all_data['BasementHalfBaths']\n",
        ")\n",
        "all_data['TotalPorchSF'] = (\n",
        "    all_data['OpenVerandaArea'] +\n",
        "    all_data['EnclosedVerandaArea'] +\n",
        "    all_data['SeasonalPorchArea'] +\n",
        "    all_data['ScreenPorchArea']\n",
        ")\n",
        "# Age and renovation features\n",
        "all_data['HotelAge'] = all_data['YearSold'] - all_data['ConstructionYear']\n",
        "all_data['RemodAge'] = all_data['YearSold'] - all_data['RenovationYear']\n",
        "all_data['WasRemodeled'] = (all_data['RemodAge'] > 0).astype(int)\n",
        "all_data['IsNew'] = (all_data['YearSold'] == all_data['ConstructionYear']).astype(int)\n",
        "# Flags for amenities\n",
        "all_data['HasPool'] = (all_data['SwimmingPoolArea'] > 0).astype(int)\n",
        "all_data['HasGarage'] = (all_data['ParkingArea'] > 0).astype(int)\n",
        "all_data['HasBasement'] = (all_data['BasementTotalSF'] > 0).astype(int)\n",
        "all_data['HasLounge'] = (all_data['Lounges'] > 0).astype(int)\n",
        "# Polynomial / interaction features\n",
        "all_data['OverallQuality_sq'] = all_data['OverallQuality']**2\n",
        "all_data['OverallQuality_cub'] = all_data['OverallQuality']**3\n",
        "all_data['OverallQuality_x_TotalSF']  = all_data['OverallQuality'] * all_data['TotalSF']\n",
        "all_data['OverallQuality_x_HotelAge'] = all_data['OverallQuality'] * all_data['HotelAge']\n",
        "# New ratio features\n",
        "all_data['BuiltPct']      = all_data['TotalSF'] / (all_data['LandArea'] + 1)\n",
        "all_data['Area_per_Room'] = all_data['UsableArea'] / (all_data['TotalRooms'] + 1)\n",
        "all_data['Baths_to_Rooms'] = all_data['TotalBath'] / (all_data['TotalRooms'] + 1)\n",
        "all_data['BasementRatio']  = all_data['BasementTotalSF'] / (all_data['TotalSF'] + 1)\n",
        "\n",
        "# ---------------------------\n",
        "# Drop Redundant Originals (after creating features)\n",
        "# ---------------------------\n",
        "drop_orig = [\n",
        "    'OpenVerandaArea','EnclosedVerandaArea','SeasonalPorchArea','ScreenPorchArea',\n",
        "    'LowQualityArea','FacadeArea','BasementFacilitySF2'\n",
        "]\n",
        "for col in drop_orig:\n",
        "    if col in all_data.columns:\n",
        "        all_data.drop(col, axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Imputation for Remaining Missing Data\n",
        "# ---------------------------\n",
        "# Many missing in RoadAccessLength; fill by District median\n",
        "if 'RoadAccessLength' in all_data.columns:\n",
        "    all_data['RoadAccessLength'] = all_data.groupby('District')['RoadAccessLength']\\\n",
        "                                          .transform(lambda x: x.fillna(x.median()))\n",
        "    # --- FIX 1 (No inplace=True) ---\n",
        "    all_data['RoadAccessLength'] = all_data['RoadAccessLength'].fillna(all_data['RoadAccessLength'].median())\n",
        "\n",
        "# Fill small gaps with zeros or modes\n",
        "if 'FacadeArea' in all_data.columns:\n",
        "    all_data['FacadeArea'].fillna(0, inplace=True) # This one is fine, not a chained assignment\n",
        "\n",
        "if 'ElectricalSystem' in all_data.columns:\n",
        "    # --- FIX 2 (No inplace=True) ---\n",
        "    all_data['ElectricalSystem'] = all_data['ElectricalSystem'].fillna(all_data['ElectricalSystem'].mode()[0])\n",
        "\n",
        "# Any remaining numeric NaNs\n",
        "num_cols = all_data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = all_data.select_dtypes(exclude=[np.number]).columns\n",
        "all_data[num_cols] = all_data[num_cols].fillna(0)\n",
        "all_data[cat_cols] = all_data[cat_cols].fillna('None')\n",
        "\n",
        "# ---------------------------\n",
        "# Ordinal Encoding for Quality Features\n",
        "# ---------------------------\n",
        "qual_map = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'None':0}\n",
        "for col in ['ExteriorQuality','ExteriorCondition','HeatingQuality','KitchenQuality']:\n",
        "    if col in all_data.columns:\n",
        "        all_data[col] = all_data[col].map(qual_map).astype(int)\n",
        "# Categorical mappings\n",
        "if 'LandSlope' in all_data.columns:\n",
        "    all_data['LandSlope'] = all_data['LandSlope'].map({'Gtl':3,'Mod':2,'Sev':1}).fillna(3).astype(int)\n",
        "if 'PlotShape' in all_data.columns:\n",
        "    all_data['PlotShape'] = all_data['PlotShape'].map({'Reg':4,'IR1':3,'IR2':2,'IR3':1}).fillna(4).astype(int)\n",
        "# Binary encoding\n",
        "all_data['CentralAC'] = all_data['CentralAC'].map({'Y':1,'N':0}).astype(int)\n",
        "\n",
        "# ---------------------------\n",
        "# Log-transform Highly Skewed Numerics\n",
        "# ---------------------------\n",
        "for col in ['ExtraFacilityValue','LandArea','BasementHalfBaths']:\n",
        "    if col in all_data.columns:\n",
        "        all_data[col] = np.log1p(all_data[col])\n",
        "\n",
        "# Drop SwimmingPoolArea due to extreme skew & rarity (we have HasPool flag)\n",
        "if 'SwimmingPoolArea' in all_data.columns:\n",
        "    all_data.drop('SwimmingPoolArea', axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# One-Hot Encoding\n",
        "# ---------------------------\n",
        "all_data = pd.get_dummies(all_data, drop_first=True)\n",
        "print(\"Final feature matrix shape:\", all_data.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# Train/Test Split for Modeling\n",
        "# ---------------------------\n",
        "X = all_data.iloc[:train.shape[0], :].values\n",
        "X_test_final = all_data.iloc[train.shape[0]:, :].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvmFi5_DjeP4",
        "outputId": "d1fabf88-83d9-4ae6-df33-62623fb6b453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature matrix shape: (1458, 233)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Models"
      ],
      "metadata": {
        "id": "GsnkXmbckQXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "cMYKqS6_kTCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Train Random Forest Model\n",
        "# ---------------------------\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "rf.fit(X, y)\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Set\n",
        "# ---------------------------\n",
        "log_preds = rf.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p if target was log-transformed\n",
        "final_preds[final_preds < 0] = 0   # avoid negative values\n",
        "\n",
        "# ---------------------------\n",
        "# Save Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"RandomForest.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53oU4cvZkVQc",
        "outputId": "6499faa7-c7cc-46c3-9133-34b88353b4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Random Forest model trained and submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  142248.956122\n",
            "1  1106  320257.951012\n",
            "2   414  113263.362772\n",
            "3   523  150685.392453\n",
            "4  1037  311892.583676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting"
      ],
      "metadata": {
        "id": "ihq7S5Zhl-2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Train Gradient Boosting Model\n",
        "# ---------------------------\n",
        "gb = GradientBoostingRegressor(\n",
        "    n_estimators=500,     # number of boosting stages\n",
        "    learning_rate=0.1,   # smaller = more robust\n",
        "    max_depth=5,          # depth of each tree\n",
        "    subsample=0.8,        # for stochastic boosting\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gb.fit(X, y)\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Set\n",
        "# ---------------------------\n",
        "log_preds = gb.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p if y was log-transformed\n",
        "final_preds[final_preds < 0] = 0   # ensure no negatives\n",
        "\n",
        "# ---------------------------\n",
        "# Save Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"GradientBoost.csv\", index=False)\n",
        "\n",
        "print(\"✅ Gradient Boosting model trained and submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK5s0-GDmBFB",
        "outputId": "b68dc7cc-c823-463b-e332-4cfa648356cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gradient Boosting model trained and submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  141322.904380\n",
            "1  1106  322125.270717\n",
            "2   414  103823.530234\n",
            "3   523  147100.911476\n",
            "4  1037  332787.447911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression"
      ],
      "metadata": {
        "id": "47IEtLx2CxGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Train Linear Regression\n",
        "# ---------------------------\n",
        "print(\"Training Linear Regression model...\")\n",
        "lin_reg = LinearRegression(n_jobs=-1)\n",
        "lin_reg.fit(X, y)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = lin_reg.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p transform\n",
        "final_preds[final_preds < 0] = 0   # ensure no negative values\n",
        "\n",
        "# ---------------------------\n",
        "# Create Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"linear_regression.csv\", index=False)\n",
        "\n",
        "print(\"✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV8375AqHrDG",
        "outputId": "42a94ca1-fbe0-4c5e-b6da-3abf34a965e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear Regression model...\n",
            "Training complete.\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147395.657115\n",
            "1  1106  328934.353821\n",
            "2   414  105309.178068\n",
            "3   523  165803.564443\n",
            "4  1037  311199.481472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-fold Cross validation"
      ],
      "metadata": {
        "id": "Cbm7mnmxI5-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# K-Fold Cross Validation Setup\n",
        "# ---------------------------\n",
        "N_FOLDS = 5\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# ---------------------------\n",
        "# Initialize Model\n",
        "# ---------------------------\n",
        "lin_reg = LinearRegression(n_jobs=-1)\n",
        "\n",
        "# ---------------------------\n",
        "# Cross-validation\n",
        "# ---------------------------\n",
        "rmsle_scores = []\n",
        "\n",
        "print(f\"Running {N_FOLDS}-Fold Cross Validation for Linear Regression...\\n\")\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y), 1):\n",
        "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
        "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "\n",
        "    lin_reg.fit(X_train, y_train)\n",
        "    y_pred = lin_reg.predict(X_valid)\n",
        "\n",
        "    rmsle = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(y_pred)))\n",
        "    rmsle_scores.append(rmsle)\n",
        "\n",
        "    print(f\"Fold {fold}: RMSLE = {rmsle:.5f}\")\n",
        "\n",
        "print(\"\\n✅ Cross-validation complete.\")\n",
        "print(f\"Average RMSLE across {N_FOLDS} folds: {np.mean(rmsle_scores):.5f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Train Final Model on Full Data\n",
        "# ---------------------------\n",
        "lin_reg.fit(X, y)\n",
        "print(\"\\nTraining final model on full dataset... Done.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = lin_reg.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ---------------------------\n",
        "# Create Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"kFold.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrHN4In8JDh8",
        "outputId": "b87083c6-bd2b-4456-ab55-2c2d52a180c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 5-Fold Cross Validation for Linear Regression...\n",
            "\n",
            "Fold 1: RMSLE = 0.12644\n",
            "Fold 2: RMSLE = 0.12862\n",
            "Fold 3: RMSLE = 0.14658\n",
            "Fold 4: RMSLE = 0.12526\n",
            "Fold 5: RMSLE = 0.12147\n",
            "\n",
            "✅ Cross-validation complete.\n",
            "Average RMSLE across 5 folds: 0.12967\n",
            "\n",
            "Training final model on full dataset... Done.\n",
            "\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147395.657115\n",
            "1  1106  328934.353821\n",
            "2   414  105309.178068\n",
            "3   523  165803.564443\n",
            "4  1037  311199.481472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOOCV"
      ],
      "metadata": {
        "id": "GsT9aA3qJp4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Leave-One-Out CV Setup\n",
        "# ---------------------------\n",
        "loo = LeaveOneOut()\n",
        "n_splits = loo.get_n_splits(X)\n",
        "\n",
        "lin_reg = LinearRegression(n_jobs=-1)\n",
        "rmsle_scores = []\n",
        "\n",
        "print(f\"Running Leave-One-Out Cross Validation on {n_splits} samples...\\n\")\n",
        "\n",
        "# ---------------------------\n",
        "# LOOCV Loop\n",
        "# ---------------------------\n",
        "for i, (train_idx, valid_idx) in enumerate(loo.split(X), 1):\n",
        "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
        "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "\n",
        "    lin_reg.fit(X_train, y_train)\n",
        "    y_pred = lin_reg.predict(X_valid)\n",
        "\n",
        "    rmsle = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(y_pred)))\n",
        "    rmsle_scores.append(rmsle)\n",
        "\n",
        "    if i % 100 == 0 or i == n_splits:  # print progress every 100 samples\n",
        "        print(f\"Processed {i}/{n_splits} samples, Current RMSLE: {rmsle:.5f}\")\n",
        "\n",
        "print(\"\\n✅ LOOCV complete.\")\n",
        "print(f\"Average RMSLE across all samples: {np.mean(rmsle_scores):.5f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Train Final Model on Full Data\n",
        "# ---------------------------\n",
        "lin_reg.fit(X, y)\n",
        "print(\"\\nTraining final Linear Regression model on full dataset... Done.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = lin_reg.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ---------------------------\n",
        "# Create Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"loocv.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE5oOpfUJrun",
        "outputId": "31220dbd-2517-4ae9-d41e-f95ac6cab85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Leave-One-Out Cross Validation on 1198 samples...\n",
            "\n",
            "Processed 100/1198 samples, Current RMSLE: 0.00944\n",
            "Processed 200/1198 samples, Current RMSLE: 0.05119\n",
            "Processed 300/1198 samples, Current RMSLE: 0.01004\n",
            "Processed 400/1198 samples, Current RMSLE: 0.06401\n",
            "Processed 500/1198 samples, Current RMSLE: 0.17141\n",
            "Processed 600/1198 samples, Current RMSLE: 0.05238\n",
            "Processed 700/1198 samples, Current RMSLE: 0.02046\n",
            "Processed 800/1198 samples, Current RMSLE: 0.07474\n",
            "Processed 900/1198 samples, Current RMSLE: 0.03780\n",
            "Processed 1000/1198 samples, Current RMSLE: 0.01810\n",
            "Processed 1100/1198 samples, Current RMSLE: 0.17214\n",
            "Processed 1198/1198 samples, Current RMSLE: 0.13056\n",
            "\n",
            "✅ LOOCV complete.\n",
            "Average RMSLE across all samples: 0.08278\n",
            "\n",
            "Training final Linear Regression model on full dataset... Done.\n",
            "\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147395.657115\n",
            "1  1106  328934.353821\n",
            "2   414  105309.178068\n",
            "3   523  165803.564443\n",
            "4  1037  311199.481472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge regression"
      ],
      "metadata": {
        "id": "vsofCZ0GKkNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Leave-One-Out CV Setup\n",
        "# ---------------------------\n",
        "loo = LeaveOneOut()\n",
        "n_splits = loo.get_n_splits(X)\n",
        "\n",
        "ridge = Ridge(alpha=1.0, random_state=42)  # You can tune alpha later\n",
        "rmsle_scores = []\n",
        "\n",
        "print(f\"Running Leave-One-Out Cross Validation for Ridge Regression on {n_splits} samples...\\n\")\n",
        "\n",
        "# ---------------------------\n",
        "# LOOCV Loop\n",
        "# ---------------------------\n",
        "for i, (train_idx, valid_idx) in enumerate(loo.split(X), 1):\n",
        "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
        "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "\n",
        "    ridge.fit(X_train, y_train)\n",
        "    y_pred = ridge.predict(X_valid)\n",
        "\n",
        "    rmsle = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(y_pred)))\n",
        "    rmsle_scores.append(rmsle)\n",
        "\n",
        "    if i % 100 == 0 or i == n_splits:  # Print progress every 100 samples\n",
        "        print(f\"Processed {i}/{n_splits} samples, Current RMSLE: {rmsle:.5f}\")\n",
        "\n",
        "print(\"\\n✅ LOOCV complete.\")\n",
        "print(f\"Average RMSLE across all samples: {np.mean(rmsle_scores):.5f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Train Final Model on Full Data\n",
        "# ---------------------------\n",
        "ridge.fit(X, y)\n",
        "print(\"\\nTraining final Ridge Regression model on full dataset... Done.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = ridge.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # Reverse log1p transform\n",
        "final_preds[final_preds < 0] = 0   # Ensure no negatives\n",
        "\n",
        "# ---------------------------\n",
        "# Create Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"ridgeRegression.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keUrKJHVKl8v",
        "outputId": "a25117b8-f254-4074-db1b-7e941b093929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Leave-One-Out Cross Validation for Ridge Regression on 1198 samples...\n",
            "\n",
            "Processed 100/1198 samples, Current RMSLE: 0.00124\n",
            "Processed 200/1198 samples, Current RMSLE: 0.06196\n",
            "Processed 300/1198 samples, Current RMSLE: 0.00458\n",
            "Processed 400/1198 samples, Current RMSLE: 0.07191\n",
            "Processed 500/1198 samples, Current RMSLE: 0.13652\n",
            "Processed 600/1198 samples, Current RMSLE: 0.04300\n",
            "Processed 700/1198 samples, Current RMSLE: 0.02222\n",
            "Processed 800/1198 samples, Current RMSLE: 0.13733\n",
            "Processed 900/1198 samples, Current RMSLE: 0.04268\n",
            "Processed 1000/1198 samples, Current RMSLE: 0.00954\n",
            "Processed 1100/1198 samples, Current RMSLE: 0.19361\n",
            "Processed 1198/1198 samples, Current RMSLE: 0.11449\n",
            "\n",
            "✅ LOOCV complete.\n",
            "Average RMSLE across all samples: 0.07832\n",
            "\n",
            "Training final Ridge Regression model on full dataset... Done.\n",
            "\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147219.487747\n",
            "1  1106  331851.841627\n",
            "2   414  104549.424486\n",
            "3   523  166146.445081\n",
            "4  1037  311794.030132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lasso Regression"
      ],
      "metadata": {
        "id": "_MT5lIWCLgop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test_final)\n",
        "\n",
        "# Lasso model\n",
        "lasso = Lasso(alpha=0.001, max_iter=50000, random_state=42)\n",
        "\n",
        "lasso.fit(X_scaled, y)\n",
        "print(\"✅ Model trained successfully (no convergence warnings).\")\n",
        "\n",
        "# Predictions\n",
        "log_preds = lasso.predict(X_test_scaled)\n",
        "final_preds = np.expm1(log_preds)\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ submission.csv created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsItkh3xLvLX",
        "outputId": "3d6a1848-57dc-4777-8010-303da3d5f5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model trained successfully (no convergence warnings).\n",
            "✅ submission.csv created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic nets"
      ],
      "metadata": {
        "id": "R4lpwqy2L7zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ================================\n",
        "# Scale features (important!)\n",
        "# ================================\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test_final)\n",
        "\n",
        "# ================================\n",
        "# Elastic Net with Cross-Validation\n",
        "# ================================\n",
        "elastic_cv = ElasticNetCV(\n",
        "    l1_ratio=[.1, .3, .5, .7, .9, .95, 1],\n",
        "    alphas=np.logspace(-4, 1, 50),\n",
        "    cv=5,\n",
        "    max_iter=100000,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training Elastic Net with CV...\")\n",
        "elastic_cv.fit(X_scaled, y)\n",
        "print(\"Training complete.\")\n",
        "print(f\"Best alpha: {elastic_cv.alpha_:.6f}\")\n",
        "print(f\"Best l1_ratio: {elastic_cv.l1_ratio_:.2f}\")\n",
        "\n",
        "# ================================\n",
        "# Predict on Test Data\n",
        "# ================================\n",
        "log_preds = elastic_cv.predict(X_test_scaled)\n",
        "final_preds = np.expm1(log_preds)\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ================================\n",
        "# Create Submission File\n",
        "# ================================\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGf3CIioL9v_",
        "outputId": "dc003c9e-3a73-410e-b4db-aae86fd2f36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Elastic Net with CV...\n",
            "Training complete.\n",
            "Best alpha: 0.028118\n",
            "Best l1_ratio: 0.10\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147540.826955\n",
            "1  1106  317283.985683\n",
            "2   414  105870.135758\n",
            "3   523  159955.124294\n",
            "4  1037  304075.633259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayesian Approach + Conjugate Priors"
      ],
      "metadata": {
        "id": "hoY8E9I8bFGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Add intercept term\n",
        "# ---------------------------\n",
        "X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "X_test_aug = np.hstack([np.ones((X_test_final.shape[0], 1)), X_test_final])\n",
        "n, p = X_aug.shape\n",
        "\n",
        "# ---------------------------\n",
        "# Prior hyperparameters\n",
        "# ---------------------------\n",
        "mu_0 = np.zeros(p)             # prior mean of coefficients\n",
        "Lambda_0 = np.eye(p) * 1e-6    # prior precision (tiny, almost uninformative)\n",
        "a_0 = 1e-6                     # prior shape for sigma^2\n",
        "b_0 = 1e-6                     # prior scale for sigma^2\n",
        "\n",
        "# ---------------------------\n",
        "# Posterior for coefficients (beta | sigma^2, y)\n",
        "# ---------------------------\n",
        "# Posterior precision and mean\n",
        "Lambda_n = Lambda_0 + X_aug.T @ X_aug\n",
        "mu_n = np.linalg.solve(Lambda_n, Lambda_0 @ mu_0 + X_aug.T @ y)\n",
        "\n",
        "# Posterior parameters for sigma^2\n",
        "a_n = a_0 + n / 2\n",
        "residuals = y - X_aug @ mu_n\n",
        "b_n = b_0 + 0.5 * (residuals.T @ residuals + (mu_n - mu_0).T @ Lambda_0 @ (mu_n - mu_0))\n",
        "\n",
        "# Posterior mean of sigma^2\n",
        "sigma2_post = b_n / (a_n - 1)\n",
        "\n",
        "# Posterior predictive mean for test set\n",
        "y_pred_test = X_test_aug @ mu_n\n",
        "\n",
        "# ---------------------------\n",
        "# Reverse log-transform\n",
        "# ---------------------------\n",
        "final_preds = np.expm1(y_pred_test)\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ---------------------------\n",
        "# Create submission file\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ Bayesian regression submission created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-cBXYcGimrG",
        "outputId": "810f171d-6037-4aba-9c98-c72935750223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Bayesian regression submission created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147395.155681\n",
            "1  1106  328934.870491\n",
            "2   414  105309.390046\n",
            "3   523  165803.205292\n",
            "4  1037  311199.689455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayesian + MAP estimate"
      ],
      "metadata": {
        "id": "cQDmUKpHoEET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Add intercept term\n",
        "# ---------------------------\n",
        "X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "X_test_aug = np.hstack([np.ones((X_test_final.shape[0], 1)), X_test_final])\n",
        "n, p = X_aug.shape\n",
        "\n",
        "# ---------------------------\n",
        "# MAP / Ridge parameters\n",
        "# ---------------------------\n",
        "tau2 = 1.0       # prior variance for coefficients\n",
        "sigma2 = 1.0     # assumed noise variance\n",
        "lambda_ = sigma2 / tau2  # regularization strength\n",
        "\n",
        "# ---------------------------\n",
        "# Compute MAP estimate\n",
        "# ---------------------------\n",
        "beta_map = np.linalg.solve(X_aug.T @ X_aug + lambda_ * np.eye(p), X_aug.T @ y)\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on test data\n",
        "# ---------------------------\n",
        "y_pred_test = X_test_aug @ beta_map\n",
        "\n",
        "# Reverse log-transform\n",
        "final_preds = np.expm1(y_pred_test)\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ---------------------------\n",
        "# Create submission file\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ Bayesian MAP regression submission created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WoTsqHwoHqT",
        "outputId": "2a0cacf2-83c7-45ef-80cc-d30d411d1d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Bayesian MAP regression submission created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  146199.896460\n",
            "1  1106  333192.071502\n",
            "2   414  105398.256957\n",
            "3   523  165257.086300\n",
            "4  1037  312337.850589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K nearest neighbours"
      ],
      "metadata": {
        "id": "N0w4v70fvpd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Scale features (important for KNN)\n",
        "# ---------------------------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test_final)\n",
        "\n",
        "# ---------------------------\n",
        "# KNN Model with Grid Search\n",
        "# ---------------------------\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]  # 1 = Manhattan, 2 = Euclidean\n",
        "}\n",
        "\n",
        "knn = KNeighborsRegressor()\n",
        "grid = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_log_error', n_jobs=-1)\n",
        "print(\"🔧 Performing Grid Search for KNN...\")\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"✅ Grid Search complete!\")\n",
        "print(f\"Best parameters: {grid.best_params_}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Train final KNN with best params\n",
        "# ---------------------------\n",
        "knn_best = grid.best_estimator_\n",
        "knn_best.fit(X_scaled, y)\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = knn_best.predict(X_test_scaled)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p\n",
        "final_preds[final_preds < 0] = 0   # ensure no negative values\n",
        "\n",
        "# ---------------------------\n",
        "# Create submission file\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGGDwnrbvrIv",
        "outputId": "3c5cf313-9b68-4c4c-e565-4b045a2f2477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Performing Grid Search for KNN...\n",
            "✅ Grid Search complete!\n",
            "Best parameters: {'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  129493.630228\n",
            "1  1106  272446.984455\n",
            "2   414  101369.955521\n",
            "3   523  139889.126281\n",
            "4  1037  334962.130438\n"
          ]
        }
      ]
    }
  ]
}